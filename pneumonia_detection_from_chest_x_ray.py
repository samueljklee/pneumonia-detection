# -*- coding: utf-8 -*-
"""Pneumonia Detection from Chest X-Ray

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VEv_Em1nf_nVzzvNIT_TqEsi8voXJI_P

# Pneumonia Detection from Chest X-Ray


- Dataset: [Chest-Xray-Pneumonia - Kaggle](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).
- Reference: [anjanatiha jupyter notebook](https://github.com/anjanatiha/Pneumonia-Detection-from-Chest-X-Ray-Images-with-Deep-Learning).
"""

"""### Import Libraries"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals
import os
import sys
import random
import time
import datetime
from collections import Counter
import numpy as np
import pandas as pd
import pathlib
import shutil
from tqdm import tqdm
import inspect
import gc
import re

from PIL import Image
import cv2

import tensorflow as tf
AUTOTUNE = tf.data.experimental.AUTOTUNE

from tensorflow import keras
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator, load_img
from keras.preprocessing.image import img_to_array, array_to_img
from keras import models
from keras.models import Model
from keras.models import Sequential
from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout
from keras.layers import GlobalAveragePooling1D, GlobalAveragePooling2D
from keras.layers import Flatten, BatchNormalization, Dense
from keras.layers import Input
from keras.constraints import maxnorm
from keras import optimizers
from keras.optimizers import Adam, SGD , RMSprop
from keras import backend as K

from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau
from keras.wrappers.scikit_learn import KerasClassifier

from sklearn.utils import class_weight
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report

from mlxtend.plotting import plot_confusion_matrix

from IPython.display import display

import seaborn as sns

from matplotlib.pyplot import figure
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# %matplotlib inline

"""### Functions Declaration"""

def reset_graph(model=None):
    if model:
        try:
            del model
        except:
            return False
    K.clear_session()
    gc.collect()
    return True


def reset_callbacks(
        checkpoint=None, 
        reduce_lr=None, 
        early_stopping=None,
        tensorboard=None 
    ):
    checkpoint = None
    reduce_lr = None
    early_stopping = None
    tensorboard = None

def show_batch(image_batch, label_batch, title=""):
    fig = plt.figure(figsize=(10,10))
    for n in range(15):
        ax = plt.subplot(5,5,n+1)
        plt.imshow(image_batch[n])
        plt.title(CLASS_NAMES[label_batch[n]==1][0])
        plt.axis('off')
    fig.suptitle(title)


def get_label(file_path):
    # convert the path to a list of path components
    parts = tf.strings.split(file_path, '/')
    # The second to last is the class-directory
    return parts[-2] == CLASS_NAMES


def decode_img(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)
    # resize the image to the desired size.
    return tf.image.resize(
            img, 
            (IMG_HEIGHT, IMG_WIDTH),
            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR
        )

def random_crop(image):
    cropped_image = tf.image.random_crop(
        image, size=(IMG_HEIGHT, IMG_WIDTH, 3))
    return cropped_image

def random_jitter(img):
    # resizing to 286 x 286 x 3
    img = tf.image.resize(
        img,
        (286, 286),
        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR
    )
    # randomly cropping to 256 x 256 x 3
    img = random_crop(img)
    # random mirroring
    img = tf.image.random_flip_left_right(img)
    return img

# normalizing the images to [-1, 1]
def normalize(img):
    img = tf.cast(img, tf.float32)
    img = (img / 127.5) - 1
    return img


def load_image_train(file_path):
    label = get_label(file_path)
    # load the raw data from the file as a string
    img = tf.io.read_file(file_path)
    img = decode_img(img)
    #img = random_jitter(img)
    #img = normalize(img)
    return img, label


def load_image_test(file_path):
    label = get_label(file_path)
    # load the raw data from the file as a string
    img = tf.io.read_file(file_path)
    img = decode_img(img)
    #img = normalize(img)
    return img, label



def plot_learning_curves(history):
    plt.figure(figsize=(12,4))

    xlabel = 'Epoch'    
    legends = ['Training', 'Validation']

    plt.subplot(1,2,1)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel(xlabel)
    plt.legend(legends, loc='upper left')
    
    plt.subplot(1,2,2)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(legends, loc='upper left')
    
    plt.tight_layout()
    

def get_confusion_matrix(y_true, y_pred_classes, confusion_matrix_file, model_title):
    precision = precision_score(y_true, y_pred_classes) 
    recall = recall_score(y_true, y_pred_classes) 
    f1 = f1_score(y_true, y_pred_classes) 

    print("-"*90)
    print("Derived Report")
    print("-"*90)
    print("%s%.2f%s"% ("Precision     : ", precision*100, "%"))
    print("%s%.2f%s"% ("Recall        : ", recall*100,    "%"))
    print("%s%.2f%s"% ("F1-Score      : ", f1*100,        "%"))
    print("-"*90)
    print("\n\n")

    CM = confusion_matrix(y_true, y_pred_classes)

    classes = CLASS_NAMES

    fig, ax = plot_confusion_matrix(
                conf_mat    = CM ,  
                figsize     = (10,8), 
                hide_ticks  = True,
                cmap        = plt.cm.Blues
            )
    plt.xticks(range(len(classes)), classes, fontsize=12)
    plt.yticks(range(len(classes)), classes, fontsize=12)
    plt.title("Confusion Matrix for Model File (Test Dataset): \n"+best_model, fontsize=11)
    plt.show()
    fig.savefig(confusion_matrix_file, dpi=100)
    cls_report_print = classification_report(y_true, y_pred_classes, target_names=classes)
    cls_report = classification_report(y_true, y_pred_classes, target_names=classes, output_dict=True)

    print("\n\n")
    print("-"*90)
    print("Report for Model File: ", model_title)
    print("-"*90)
    print(cls_report_print)
    print("-"*90)

"""### Preprocessing"""

reset_graph()
reset_callbacks()

# Initialize Variables

root_dir = "./"
dataset_root_dir = r"chest_xray/"

# Input dir
train_dir   = pathlib.Path(dataset_root_dir + r"train")
test_dir    = pathlib.Path(dataset_root_dir + r"test")
val_dir     = pathlib.Path(dataset_root_dir + r"val")

# Output dir
output_dir          = root_dir + r"data/output/"
output_figures_dir  = output_dir + "figures"

temp = root_dir
for d in output_figures_dir.split('/'):
    temp += d + "/"
    if not os.path.exists(temp):
        os.mkdir(temp)

# The 1./255 is to convert from uint8 to float32 in range [0,1].
RESCALE     = 1./255
BATCH_SIZE  = 64
IMG_HEIGHT  = 150
IMG_WIDTH   = 150
IMG_SHAPE   = (IMG_HEIGHT, IMG_WIDTH, 3)
TARGET_SIZE = (IMG_HEIGHT, IMG_WIDTH)
SHUFFLE_BUFFER_SIZE = 6000

train_data_count    = len(list(train_dir.glob('*/*.jpeg')))
test_data_count     = len(list(test_dir.glob('*/*.jpeg')))
val_data_count      = len(list(val_dir.glob('*/*.jpeg')))
TOTAL_IMAGE_COUNT         = train_data_count + test_data_count + val_data_count

STEPS_PER_EPOCH = np.ceil(TOTAL_IMAGE_COUNT/BATCH_SIZE)

# Training, Testing, Validation Data

print("Total images count       : ", TOTAL_IMAGE_COUNT)
print("Training data count      : ", train_data_count)
print("Testing data count       : ", test_data_count)
print("Validation data count    : ", val_data_count)

train_class_name    = np.array([item.name for item in train_dir.glob('*') if item.name != "LICENSE.txt"])
test_class_name     = np.array([item.name for item in train_dir.glob('*') if item.name != "LICENSE.txt"])
val_class_name      = np.array([item.name for item in val_dir.glob('*') if item.name != "LICENSE.txt"])

print("Training data classes    : ", train_class_name)
print("Testing data classes     : ", test_class_name)
print("Validation data classes  : ", val_class_name)

CLASS_NAMES = np.unique(train_class_name)
CLASS_COUNT = len(CLASS_NAMES)
CLASS_DICT  = {idx:key for idx, key in enumerate(CLASS_NAMES)}
print("Class names              : ", CLASS_NAMES)
print("Class dict               : ", CLASS_DICT)

# Load using tf.data
"""
The above keras.preprocessing method is convienient, but has two downsides:
    It's slow. 
    It lacks fine-grained control.
    It is not well integrated with the rest of TensorFlow.
"""

train_dir_ = str(train_dir/'*/*')
val_dir_ = str(val_dir/'*/*')
test_dir_ = str(test_dir/'*/*')

train_dataset = tf.data.Dataset.list_files(train_dir_)
train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE)
train_dataset = train_dataset.map(
        load_image_train, 
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    )
train_dataset = train_dataset.batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.list_files(val_dir_)
val_dataset = val_dataset.shuffle(SHUFFLE_BUFFER_SIZE)
val_dataset = val_dataset.map(load_image_test)
val_dataset = val_dataset.batch(val_data_count)

test_dataset = tf.data.Dataset.list_files(test_dir_)
test_dataset = test_dataset.shuffle(SHUFFLE_BUFFER_SIZE)
test_dataset = test_dataset.map(load_image_test)
test_dataset = test_dataset.batch(test_data_count)
train_dataset, val_dataset, test_dataset

"""### Image Processing, Augmentation, Transformation for Datasets"""

for image, label in train_dataset.take(1):
    print("Train Image shape: ", image.numpy().shape)
    print("Label: ", label.numpy())
for image, label in val_dataset.take(1):
    print("Validation Image shape: ", image.numpy().shape)
    print("Label: ", label.numpy())
for image, label in test_dataset.take(1):
    print("Test Image shape: ", image.numpy().shape)
    print("Label: ", label.numpy())
    
del image, label

train_image_batch, train_label_batch = next(iter(train_dataset.take(5)))

plt.figure(figsize=(5, 3))

y_train_classes = np.argmax(train_label_batch, axis = 1)

plt.subplot(1,2,1).set_title('NORMAL')
plt.imshow(train_image_batch[np.argmax(y_train_classes == 0)])

plt.subplot(1,2,2).set_title('PNEUMONIA')
plt.imshow(train_image_batch[np.argmax(y_train_classes == 1)])

plt.tight_layout()

del train_image_batch, train_label_batch, y_train_classes

# Inspect a batch of data
train_image_batch, train_label_batch = next(iter(train_dataset.take(1)))
show_batch(train_image_batch.numpy(), train_label_batch.numpy(), "Train Dataset")

val_image_batch, val_label_batch = next(iter(val_dataset))
show_batch(val_image_batch.numpy(), val_label_batch.numpy(), "Validation Dataset")

test_image_batch, test_label_batch = next(iter(test_dataset))
show_batch(test_image_batch.numpy(), test_label_batch.numpy(), "Test Dataset")

plt.subplot(1,3,1)
sns.countplot(np.argmax(train_label_batch.numpy(), axis=1)).set_title('TRAIN')

plt.subplot(1,3,2)
sns.countplot(np.argmax(val_label_batch.numpy(), axis=1)).set_title('VALIDATION')

plt.subplot(1,3,3)
sns.countplot(np.argmax(test_label_batch.numpy(), axis=1)).set_title('TEST')

plt.tight_layout()

"""### Training Files Configuration"""

# Use unix commands since it's easier
model_dir   = output_dir + r"models/"
log_dir     = output_dir + r"logs/"

if os.path.exists(model_dir):
    if len(os.listdir(model_dir)):
        ! rm -r {model_dir}*
else:
    ! mkdir {model_dir}

if os.path.exists(log_dir):
    if len(os.listdir(log_dir)):
        ! rm -r {log_dir}*
else:
    ! mkdir {log_dir}

curr_model_dir = model_dir + time.strftime('%Y-%m-%d_%H-%M-%S') + "/"
curr_log_dir = log_dir + time.strftime('%Y-%m-%d_%H-%M-%S')
print("Creating folders: ", curr_model_dir, curr_log_dir)

if os.path.exists(curr_model_dir):
    if len(os.listdir(curr_model_dir)):
        ! rm -r {curr_model_dir}*
else:
    ! mkdir {curr_model_dir}

if os.path.exists(curr_log_dir):
    if len(os.listdir(curr_log_dir)):
        ! rm -r {curr_log_dir}*
else:
    ! mkdir {curr_log_dir}

"""### Callbacks"""

reset_graph()
reset_callbacks()

# https://keras.io/callbacks/

def get_callbacks(model_name=""):
    checkpoint = ModelCheckpoint(
            model_name, 
            monitor='val_loss', 
            save_best_only=True
        )

    early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=10,
            verbose=1,
            restore_best_weights=True
        )

    tensorboard = TensorBoard(
            log_dir=log_dir,
            update_freq = 'batch'
        )

    reduce_lr = ReduceLROnPlateau(
            monitor='val_loss',
            patience=1,
            factor=0.2,
            min_lr=0.0000000001,
            verbose=1
        )

    return [checkpoint]#, reduce_lr, early_stopping, tensorboard]

model_name = curr_model_dir + "epoch_{epoch:02d}-val_loss_{val_loss:.2f}.hdf5"
callbacks = get_callbacks(model_name)

"""### Model Configurations using Pre-trained Models"""

# https://www.tensorflow.org/tutorials/images/transfer_learning
# https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5
# https://www.quora.com/What-is-the-meaning-of-flattening-step-in-a-convolutional-neural-network
# https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes

#InceptionV3 vgg16
pretrained_model = tf.keras.applications.vgg16.VGG16(
        weights='imagenet', 
        include_top=False, 
        input_shape=IMG_SHAPE,
    )

# Freeze the convolutional base created from the previous step and use that as a feature extractor
# add a classifier on top of it and train the top-level classifier.
pretrained_model.trainable = False

model = tf.keras.Sequential([
    pretrained_model,

    # Add classsification head
    # To generate predictions from the block of features
    # average over the spatial 5x5 spatial locations
    # using a tf.keras.layers.GlobalAveragePooling2D layer to 
    # convert the features to a single 1280-element vector per image.
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Flatten(),
    #tf.keras.layers.Dense(256, activation='relu'),

    # Apply a tf.keras.layers.Dense layer to convert these features into a single prediction per image. 
    # Don't need an activation function here because this prediction will be treated as a logit, 
    # or a raw prediction value. 
    # Positive numbers predict class 1, negative numbers predict class 0.
    tf.keras.layers.Dense(2, activation='softmax'),
])

model.summary()

for idx, layer in enumerate(model.layers):
    print("layer {}: {}, trainable: {}".format(idx, layer.name, layer.trainable))

# The 31M parameters in InceptionV3 are frozen, 
# but there are 2K trainable parameters in the Dense layer. 
# These are divided between two tf.Variable objects, the weights and biases.
model.trainable_weights

INITIAL_LEARNING_RATE = 1e-4
optimizer = tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE)
loss = 'categorical_crossentropy'
metrics = ['accuracy']

model.compile(
    loss=loss,     
    optimizer=optimizer, 
    metrics=metrics
)

y_labels = np.argmax(next(iter(train_dataset))[1].numpy(), axis=1)
classweight = class_weight.compute_class_weight('balanced', np.unique(y_labels), y_labels)
print(classweight)

INITIAL_EPOCH = 10
history = model.fit(
        train_dataset,
        class_weight = classweight,
        callbacks = callbacks,
        shuffle = True,
        validation_data = val_dataset,
        epochs = INITIAL_EPOCH,
        verbose = 1
    )

"""### Model Performance Visualization over Epochs"""

print(history.history.keys())

plot_learning_curves(history)

"""### Evaluating Model"""

# Choose the model with least validation loss

def get_best_model(history):
    idx = np.argmin(history.history['val_loss']) 
    print("Loading the best model")
    best_model_epoch = idx + 1
    best_model_val_loss = history.history['val_loss'][idx]
    best_model_val_acc = history.history['val_accuracy'][idx]
    return best_model_epoch, best_model_val_loss, best_model_val_acc


best_model_epoch, best_model_val_loss, best_model_val_acc = get_best_model(history)
print("epoch: {}, val_loss: {}, val_acc: {}".format(best_model_epoch, best_model_val_loss, best_model_val_acc))
best_model = model_name.format(
                epoch   =   best_model_epoch,
                val_loss=   round(best_model_val_loss, 2)
            )
best_model

print("Loading best_model: ", best_model)
try:
    model.load_weights(best_model)
except Exception as e:
    print("Fail to laod model. Error: ", e)
print("Loaded.")

x_test, y_test = next(iter(test_dataset))
score = model.evaluate(x_test.numpy(), y_test.numpy(), verbose=0)
print('Model Loss: {}, Accuracy: {}'.format(score[0], score[1]))

# Confusion Matrix of the model

y_pred = model.predict(x_test.numpy())
y_pred_classes = np.argmax(y_pred, axis = 1) 
y_true = np.argmax(y_test.numpy(), axis = 1) 

confusion_matrix_file = output_figures_dir+"/confusion_matrix"
get_confusion_matrix(y_true, y_pred_classes, confusion_matrix_file, best_model)

"""### Fine Tuning
- Since dataset is small and different from pre-trained model's dataset
   
    - train some layers and leave some frozen
    - lower learning rate
    - increase epochs
"""

pretrained_model.trainable = True
for layer in pretrained_model.layers[:15]:
    layer.trainable = False
for idx, layer in enumerate(pretrained_model.layers):
    print("layer {}: {}, trainable: {}".format(idx, layer.name, layer.trainable))

fine_tune_model = tf.keras.Sequential([
    pretrained_model,
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(2, activation='softmax'),
])

FINE_TUNE_LEARNING_RATE = INITIAL_LEARNING_RATE / 10

optimizer   = tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LEARNING_RATE)
loss        = 'categorical_crossentropy'
metrics     = ['accuracy']

fine_tune_model.compile(
    loss=loss,     
    optimizer=optimizer, 
    metrics=metrics
)

fine_tune_model.summary()

for idx, layer in enumerate(fine_tune_model.layers):
    print("layer {}: {}, trainable: {}".format(idx, layer.name, layer.trainable))

reset_graph()
reset_callbacks()
fine_tune_model_name = curr_model_dir + "new_epoch_{epoch:02d}-val_loss_{val_loss:.2f}.hdf5"
callbacks = get_callbacks(model_name=fine_tune_model_name)

FINE_TUNE_EPOCHS = 10
TOTAL_EPOCHS =  INITIAL_EPOCH + FINE_TUNE_EPOCHS

fine_tune_history = fine_tune_model.fit(
        train_dataset,
        class_weight = classweight,
        callbacks = callbacks,
        shuffle = True,
        validation_data = val_dataset,
        epochs = TOTAL_EPOCHS,
        verbose=1
    )

plot_learning_curves(fine_tune_history)

best_model_epoch, best_model_val_loss, best_model_val_acc = get_best_model(fine_tune_history)
print("epoch: {}, val_loss: {}, val_acc: {}".format(best_model_epoch, best_model_val_loss, best_model_val_acc))
best_fine_tune_model = fine_tune_model_name.format(
                epoch   =   best_model_epoch,
                val_loss=   round(best_model_val_loss, 2)
            )
best_fine_tune_model

print("Loading best_model: ", best_fine_tune_model)
try:
    fine_tune_model.load_weights(best_fine_tune_model)
except Exception as e:
    print("Fail to laod model. Error: ", e)
print("Loaded.")

score = fine_tune_model.evaluate(x_test.numpy(), y_test.numpy(), verbose=0)
print('Model Loss: {}, Accuracy: {}'.format(score[0], score[1]))

y_pred = fine_tune_model.predict(x_test.numpy())
y_pred_classes = np.argmax(y_pred, axis = 1) 
y_true = np.argmax(y_test.numpy(), axis = 1) 

confusion_matrix_file = output_figures_dir+"/fine_tune_confusion_matrix"
get_confusion_matrix(y_true, y_pred_classes, confusion_matrix_file, best_fine_tune_model)

"""Note: 
- Reducing learning rate by a factor of 10

    - **Accuracy increase** by **1%**. **81.09%** -> **82.37%**
    - Pneumonia **precision increased** by **1%**
    - Normal **recall increase** by **4%**

### Visualizing Test Dataset Result
"""

fig = plt.figure(figsize=(13,17))

for i in range(25):
    predicted = y_pred_classes[i]
    original = y_true[i]
    title_text = ("%s%s%s%s%s"%("True: ", original, "\n", "Pred: ", predicted))
    
    ax = fig.add_subplot(5, 5, i+1)

    if original == predicted:
        ax.set_title(title_text)
    else:
        ax.set_title(title_text, color='red')

    ax.imshow(x_test[i].numpy())

test_pred_result_file = output_figures_dir+"/fine_tune_test_prediction_results"
fig.savefig(test_pred_result_file, dpi=100)
plt.show()

"""### Last few words...
- Spent almost a week on this from begin to end.
- Faced a ton of issues such as: 

    - input dataset format issues
    - dealing with tensors
    - migrating to `Tensorflow 2` from `Tensorflow 1`
    - image preprocessing
    - dealing with insufficient new dataset
    - model configurations
    - model overfitting especially with `InceptionV3`. According to some Google searches: most probably the amount of new dataset isn't sufficient, therefore the massive weights that `InceptionV3` couldn't converge (?).
    - ...

- Things I could do differently if I have more time:

    - Hyperparameter tweaking using [`tensorboard's hparams`](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams)
    - Utilize `tf.keras.preprocessing.image.ImageDataGenerator`?
"""